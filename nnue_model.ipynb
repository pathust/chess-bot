{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"data/chessData.csv\"  \n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_evaluation(value):\n",
    "    value = str(value).strip()\n",
    "    if value.startswith(\"#\"):  # Checkmate cases\n",
    "        return 20000 if \"+\" in value else -20000\n",
    "    return float(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Evaluation\"] = df[\"Evaluation\"].apply(process_evaluation).astype(np.float32)  # Changed to float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Evaluation to [-1000, 1000]\n",
    "eval_max = df[\"Evaluation\"].abs().max()\n",
    "df[\"Evaluation\"] = (df[\"Evaluation\"] / eval_max) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "def encoding(fen):\n",
    "    piece_map = {\"p\": -1, \"n\": -2, \"b\": -3, \"r\": -4, \"q\": -5, \"k\": -6,\n",
    "                 \"P\": 1, \"N\": 2, \"B\": 3, \"R\": 4, \"Q\": 5, \"K\": 6}\n",
    "    board, turn = fen.split()[:2]  # Get board state and move turn\n",
    "    encoded_halfka = np.zeros(128, dtype=np.float32)\n",
    "    encoded_halfkp = np.zeros(128, dtype=np.float32)\n",
    "    \n",
    "    squares = []\n",
    "    king_pos = {\"w\": None, \"b\": None}  # White and Black King positions\n",
    "\n",
    "    for row in board.split(\"/\"):\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                squares.extend([None] * int(char))\n",
    "            else:\n",
    "                squares.append(char)\n",
    "    \n",
    "    for i, piece in enumerate(squares):\n",
    "        if piece == \"K\":\n",
    "            king_pos[\"w\"] = i\n",
    "        elif piece == \"k\":\n",
    "            king_pos[\"b\"] = i\n",
    "    \n",
    "    side_to_move = \"w\" if turn == \"w\" else \"b\"\n",
    "    king_idx = king_pos[side_to_move]  # King position of the side to encode\n",
    "    \n",
    "    for i, piece in enumerate(squares):\n",
    "        if piece:\n",
    "            encoded_halfka[i * 2] = np.float16(piece_map[piece])\n",
    "            encoded_halfka[i * 2 + 1] = np.float16(1.0 if piece.isupper() else -1.0)\n",
    "            \n",
    "            if piece.lower() == \"p\":\n",
    "                encoded_halfkp[i * 2] = np.float16(piece_map[piece])\n",
    "                encoded_halfkp[i * 2 + 1] = np.float16(1.0 if piece.isupper() else -1.0)\n",
    "\n",
    "    return np.concatenate([encoded_halfka, encoded_halfkp]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0. -5. -1. -4. -1.  0.  0. -4. -1.  0.  0. -6. -1.  0.  0. -1. -1.\n",
      " -3. -1.  0.  0. -1. -1. -1. -1. -1. -1.  0.  0. -1. -1.  0.  0. -1. -1.\n",
      " -2. -1. -3. -1.  0.  0.  0.  0. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0. -2. -1.  0.  0.  0.  0.  1.  1.  2.  1.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  2.  1.  0.  0.  3.  1.\n",
      "  1.  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.  5.  1.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1.  0.  0.  0.  0.  4.  1.  4.  1.  0.  0.  3.  1.  6.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " -1. -1.  0.  0.  0.  0. -1. -1. -1. -1. -1. -1.  0.  0. -1. -1.  0.  0.\n",
      " -1. -1.  0.  0.  0.  0.  0.  0.  0.  0. -1. -1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.\n",
      "  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(encoding(\"1qr1r1k1/pb1ppp1p/1pnb2p1/7n/2PNP3/1PN1BPP1/P2Q3P/2RR1BK1 w - - 1 17\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming x_data is your list of vectors\n",
    "# Example: x_data = [np.array([1,2,3]), np.array([4,5,6])]\n",
    "\n",
    "# Save the encodings to a file\n",
    "def save_encodings(x_data, filename='encodings.txt'):\n",
    "    # Convert numpy arrays to lists for JSON serialization\n",
    "    serializable_data = [x.tolist() if isinstance(x, np.ndarray) else x for x in x_data]\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(serializable_data, f)\n",
    "    \n",
    "    print(f\"Encodings saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the encodings from a file\n",
    "def load_encodings(filename='encodings.txt'):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Convert lists back to numpy arrays if needed\n",
    "    x_data = [np.array(x) for x in data]\n",
    "    \n",
    "    print(f\"Loaded {len(x_data)} encodings from {filename}\")\n",
    "    return x_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500000 rows\n",
      "Processed 1000000 rows\n",
      "Processed 1500000 rows\n",
      "Processed 2000000 rows\n",
      "Processed 2500000 rows\n",
      "Processed 3000000 rows\n",
      "Processed 3500000 rows\n",
      "Processed 4000000 rows\n",
      "Processed 4500000 rows\n",
      "Processed 5000000 rows\n",
      "Processed 5500000 rows\n",
      "Processed 6000000 rows\n",
      "Processed 6500000 rows\n",
      "Processed 7000000 rows\n",
      "Processed 7500000 rows\n",
      "Processed 8000000 rows\n",
      "Processed 8500000 rows\n",
      "Processed 9000000 rows\n",
      "Processed 9500000 rows\n",
      "Processed 10000000 rows\n",
      "Processed 10500000 rows\n",
      "Processed 11000000 rows\n",
      "Processed 11500000 rows\n",
      "Processed 12000000 rows\n",
      "Processed 12500000 rows\n"
     ]
    }
   ],
   "source": [
    "# Apply encoding and gradually delete data to optimize memory\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "drop_interval = 500000\n",
    "drop_indices = []\n",
    "x_min, x_max = None, None\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    encoded = encoding(row[\"FEN\"])\n",
    "    x_data.append(encoded)\n",
    "    y_data.append(row[\"Evaluation\"])\n",
    "    drop_indices.append(index)\n",
    "    \n",
    "    if x_min is None:\n",
    "        x_min, x_max = encoded.copy(), encoded.copy()\n",
    "    else:\n",
    "        x_min = np.minimum(x_min, encoded)\n",
    "        x_max = np.maximum(x_max, encoded)\n",
    "    \n",
    "    if len(drop_indices) >= drop_interval:\n",
    "        df.drop(drop_indices, inplace=True)\n",
    "        drop_indices = []\n",
    "        print(f\"Processed {index + 1} rows\")\n",
    "\n",
    "df = None  # Free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chuyển x_data thành numpy array để dễ thao tác\n",
    "# x_data = np.array(x_data, dtype=np.float32)\n",
    "\n",
    "# # Tính mean và std theo từng feature (trục 0)\n",
    "# mean = np.mean(x_data, axis=0)\n",
    "# std = np.std(x_data, axis=0)\n",
    "\n",
    "# # Tránh chia cho 0 nếu std quá nhỏ\n",
    "# std[std == 0] = 1e-8  \n",
    "\n",
    "# # Chuẩn hóa dữ liệu\n",
    "# x_data = (x_data - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "# Save encodings\n",
    "# save_encodings(x_data)\n",
    "\n",
    "# Later in your code or in another session, load the encodings\n",
    "# loaded_data = load_encodings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch Tensor and manually standard scale\n",
    "x_data = np.vstack(x_data).astype(np.float16)\n",
    "y_data = np.array(y_data, dtype=np.float16).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values found in x_data.\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values before scaling\n",
    "if np.isnan(x_data).any():\n",
    "    print(\"Warning: x_data contains NaN values!\")\n",
    "else:\n",
    "    print(\"No NaN values found in x_data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = (x_data - x_min) / (x_max - x_min + 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dữ liệu từ RAM (chỉ thực hiện một lần trước khi lưu)\n",
    "x_data = np.array(x_data, dtype=np.float16)\n",
    "y_data = np.array(y_data, dtype=np.float16)\n",
    "\n",
    "# Shuffle dữ liệu trước khi lưu\n",
    "indices = np.arange(len(y_data))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_data = y_data[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu xuống file để đọc từ ổ cứng khi train\n",
    "np.save(\"x_data.npy\", x_data)\n",
    "np.save(\"y_data.npy\", y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Giải phóng bộ nhớ\n",
    "del x_data, y_data\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for NaN values before scaling\n",
    "# if np.isnan(x_data).any():\n",
    "#     print(\"Warning: x_data contains NaN values!\")\n",
    "# else:\n",
    "#     print(\"No NaN values found in x_data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to PyTorch Tensor\n",
    "# x_data = torch.tensor(x_data, dtype=torch.float16)\n",
    "# y_data = torch.tensor(y_data, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, x_file, y_file):\n",
    "        self.x_data = np.load(x_file, mmap_mode='r')  \n",
    "        self.y_data = np.load(y_file, mmap_mode='r')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y_data) \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x_data[idx].astype(np.float32)\n",
    "        y = self.y_data[idx].astype(np.float32)\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "# Tạo DataLoader\n",
    "batch_size = 128\n",
    "dataset = ChessDataset(\"x_data.npy\", \"y_data.npy\")\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNUE(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NNUE, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)  # Thêm BatchNorm\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.relu(self.bn4(self.fc4(x)))\n",
    "        return self.fc5(x)\n",
    "# Khởi tạo mô hình với kích thước input lấy từ file\n",
    "x_sample = np.load(\"x_data.npy\", mmap_mode='r')[0]\n",
    "model = NNUE(input_size=len(x_sample)).to(\"cuda\" if torch.cuda.is_available() else \"cpu\").float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng giá trị 0 trên từng chiều của vector:\n",
      " [   45434  4155546   140813  1851819   309110  3181555    88056  3452432\n",
      "   934260  3141716   391262  4280386  6081824  6479623   710162  1990693\n",
      "    27836  4582928    59672  5522287   117918  3063382   184248  3132908\n",
      "   327471  3851872   406830  7821089   849773  7803385   498150  6768671\n",
      "    15282  3723906    42329  2906374    80266  3421127   135929  4640880\n",
      "   178299  4234874   238038  4541000   175192  5534493    97310  3470321\n",
      "     9880  1985013    23899  1661620    45020  3767617    73593  2490921\n",
      "    90987  3092336    87984  2015484    63846  1319801    33599  1608650\n",
      "     7890   619680    17959  1283534    26813  1060191    35387  1067387\n",
      "    39060  1017914    38304   772455    32596   762514    17548   527772\n",
      "     5748   283462    12361   313831    14472   374922    17287   381355\n",
      "    17251   262012    18808   239385    16980   177762     8931   216667\n",
      "     3237   228371     6264   289869     6714   219775     6326   194037\n",
      "     7540   168647     8219   147646     7403   102901     4315    96038\n",
      "     1144    99121     1892    84833     1990    96213     2186   105487\n",
      "     2297    92502     2844    61285     2457    44447     1540    46232\n",
      " 12958035 12958035 12958035 12958035 12958035 12958035 12958035 12958035\n",
      " 12958035 12958035 12958035 12958035 12958035 12958035 12958035 12958035\n",
      "  4091690  4091690  4355164  4355164  1452949  1452949   272069   272069\n",
      "  1277391  1277391  6939627  6939627  4672979  4672979  6032385  6032385\n",
      "  3040384  3040384  1684297  1684297  1840831  1840831  3625508  3625508\n",
      "  3090872  3090872  1268046  1268046  4751399  4751399  3115122  3115122\n",
      "  1415524  1415524  1330361  1330361  2898903  2898903  1518513  1518513\n",
      "  2186998  2186998  1341610  1341610   982670   982670  1147848  1147848\n",
      "   374800   374800   689472   689472   631492   631492   459324   459324\n",
      "   478028   478028   392752   392752   287876   287876   310443   310443\n",
      "   102464   102464    99220    99220   110583   110583    96158    96158\n",
      "    70344    70344    74752    74752    52467    52467    69948    69948\n",
      "    25678    25678    33268    33268    31506    31506    25881    25881\n",
      "    18094    18094    17130    17130    15407    15407    18192    18192\n",
      " 12958035 12958035 12958035 12958035 12958035 12958035 12958035 12958035\n",
      " 12958035 12958035 12958035 12958035 12958035 12958035 12958035 12958035]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load dữ liệu mà không cần đưa toàn bộ vào RAM\n",
    "x_data = np.load(\"x_data.npy\", mmap_mode='r')\n",
    "\n",
    "# Đếm số lượng chiều có giá trị bằng 0 trên tất cả các vector\n",
    "zero_counts = np.sum(x_data == 0, axis=0)\n",
    "\n",
    "# In kết quả\n",
    "print(\"Số lượng giá trị 0 trên từng chiều của vector:\\n\", zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m zero_counts = np.sum(\u001b[43mx_data\u001b[49m == \u001b[32m0\u001b[39m, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "zero_counts = np.sum(x_data == 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình loss function và optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "num_epochs = 100\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
    "    \n",
    "    # Lưu mô hình tốt nhất\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), \"best_nnue.pth\")\n",
    "        print(\"Model saved!\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
